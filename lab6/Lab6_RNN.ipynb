{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dqb6_SeUfkG7"
   },
   "source": [
    "# Lab 6: RNNs & Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjF-YUyqACXt"
   },
   "source": [
    "Author: Ravi C, Ren Yi\n",
    "\n",
    "Edit by Long Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "kOjobxhbfkHA",
    "outputId": "70660689-231b-443a-b8d1-cfd61c1c49c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n",
      "Device being used: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/longchen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device being used: %s\" %device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YrCdiD7fkHD"
   },
   "source": [
    "## Goal:\n",
    "- Understand the mechanics of RNNs in Pytorch\n",
    "- Train RNN based neural networks on text data\n",
    "- Basics of word embedding and how to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97W7LJNtfkHE",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Problem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClzLmAhAfkHE"
   },
   "source": [
    "### Dataset\n",
    "Download the two files in the data folder [here](https://drive.google.com/drive/folders/1KBUyfU87zz8eOZwr2ifDi2Z4LBHlSZ28?usp=sharing). Save the folder in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fludClYgfkHF"
   },
   "source": [
    "For the first part, we will be using the [First GOP Debate Twitter Sentiment dataset](https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras/data), which contains Tweets after the first GOP debate and their sentiments (among other stuff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "KqNi_76ofkHG",
    "outputId": "d6d50053-05c1-458e-e20d-25467b854450"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold  \\\n",
       "0                     1.0000            NaN  ...              NaN   \n",
       "1                     1.0000            NaN  ...              NaN   \n",
       "2                     0.6629            NaN  ...              NaN   \n",
       "3                     0.7039            NaN  ...              NaN   \n",
       "4                     1.0000            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0             5             NaN                 NaN   \n",
       "1            26             NaN                 NaN   \n",
       "2            27             NaN                 NaN   \n",
       "3           138             NaN                 NaN   \n",
       "4           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1111)\n",
    "\n",
    "df = pd.read_csv('data/Sentiment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JD_GW-x3fkHK"
   },
   "source": [
    "Let's first look at some basic intuition and stats of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-saQCovdfkHL",
    "outputId": "0beab833-3243-440d-f22a-48eebded99d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @NancyLeeGrahn: How did everyone feel about the Climate Change question last night? Exactly. #GOPDebate'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data is a string of words\n",
    "df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "GhFdZwoSfkHO",
    "outputId": "c1266849-dcb5-4a1f-f722-9192f3e31e71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>8493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>3142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>2236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "sentiment      \n",
       "Negative   8493\n",
       "Neutral    3142\n",
       "Positive   2236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby('sentiment').count()['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WL4LqQE1fkHR"
   },
   "source": [
    "For simplicity, \n",
    "- we only use ```X = 'sentiment'``` and ```y = 'text'``` from the original dataframe. \n",
    "- We only look at positive (1) and negative (0) tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "tiJMS1ZafkHT",
    "outputId": "5158c4b5-c011-4b0a-94fb-a267053a6c18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "sentiment      \n",
       "0          8493\n",
       "1          2236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['sentiment', 'text']]\n",
    "df = df[df['sentiment'] != 'Neutral']\n",
    "df['sentiment'] = [1 if s == \"Positive\" else 0 for s in df['sentiment']]\n",
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "dF6uRJORfkHX",
    "outputId": "1013243e-2c27-416d-b886-8cc3e480b58f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.152858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.847142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "sentiment           \n",
       "0          79.152858\n",
       "1          20.847142"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.10, random_state=42)\n",
    "train_data.index = np.arange(len(train_data))\n",
    "test_data.index = np.arange(len(test_data))\n",
    "train_data.groupby('sentiment').count().apply(lambda x: 100 * x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZXy_udKfkHa"
   },
   "source": [
    "### Input representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxCfQbRKfkHb"
   },
   "source": [
    "#### Build vocabulary\n",
    "We need to build a vocabulary using words in our training data. Any words in the test set that are not in our vocabulary will be replaced with an ```<UNK>``` token. We will also add a ```<PAD>``` token as padding.\n",
    "\n",
    "For computational purposes, we'll only take words that appeared more than 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qaZ_8lblfkHc",
    "outputId": "b0f88f5b-507f-4386-b2a7-fabe2d2cd7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3069\n"
     ]
    }
   ],
   "source": [
    "UNK = \"<UNK>\"\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "def build_vocab(sentences, min_count=3, max_vocab=None):\n",
    "    \"\"\"\n",
    "    Build vocabulary from sentences (list of strings)\n",
    "    \"\"\"\n",
    "    # keep track of the number of appearance of each word\n",
    "    word_count = Counter()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Regular expression operations: [] (indicate a set of characters), \n",
    "        sentence = re.sub('[\\\\(\\[#.!?,\\'\\/\\])0-9]', ' ', sentence)\n",
    "        word_count.update(word_tokenize(sentence.lower()))\n",
    "    \n",
    "    vocabulary = list([w for w in word_count if word_count[w] > min_count]) + [UNK, PAD]\n",
    "    indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    return vocabulary, indices\n",
    "\n",
    "vocabulary, vocab_indices = build_vocab(train_data['text'])\n",
    "\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qo-WXkDBfkHf"
   },
   "source": [
    "## Model Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4vIjTqefkHg"
   },
   "source": [
    "#### Word representations\n",
    "Next, we neeed to convert each word/token in the sentences into its index in the vocabulary so that pytorch can use it. We do this for both train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvBthg06fkHh"
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rL3LK19wfkHi"
   },
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, vocab_index, df, label = 'sentiment'):\n",
    "        self.vocab_index = vocab_index\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        sentence = self.df.loc[key, 'text']\n",
    "        sentence = re.sub('[\\\\(\\[#.!?,\\'\\/\\])0-9]', ' ', sentence)\n",
    "        token_indices = np.array([self.vocab_index[word] if word in self.vocab_index else self.vocab_index['<UNK>'] for word in word_tokenize(sentence.lower())])\n",
    "        return (torch.tensor(token_indices) , self.df.loc[key, self.label])\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    \n",
    "    # I want to    eat an     apple\n",
    "    # I am   going to  sleep  PAD  \n",
    "    # batch_first: output will be in B x T x * if True, or in T x B x * otherwise\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=len(vocabulary)-1)\n",
    "\n",
    "    return torch.as_tensor(xx_pad), torch.as_tensor(x_lens), torch.LongTensor(yy)\n",
    "    \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# shuffle: set to True to have the data reshuffled at every epoch\n",
    "train_loader = DataLoader(TweetDataset(vocab_indices, train_data),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          collate_fn = pad_collate)\n",
    "test_loader = DataLoader(TweetDataset(vocab_indices, test_data),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a general idea of what an instance of training batch will be like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************Padded sequence*********************************\n",
      "tensor([  30,   17, 3067,   31,   95,  946,   87, 1029,    1, 1767, 1768,    5,\n",
      "         265,   37,   93,   17, 1267,   48,  343,  594,   90,  354,   51,  627,\n",
      "          93,   32, 3068, 3068, 3068, 3068])\n",
      "*******************************Length of sequence*******************************\n",
      "tensor([26, 30, 12, 22, 26, 20, 28, 22, 19, 27, 25, 21, 21, 15, 23, 30, 30, 23,\n",
      "        26, 21, 13, 22, 15, 21, 25, 27, 28, 26, 22, 18, 19, 21])\n",
      "*******************************Label of sequence********************************\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "sample_input = next(iter(train_loader))\n",
    "print(\"Padded sequence\".center(80, '*'))\n",
    "print(sample_input[0][0])\n",
    "print(\"Length of sequence\".center(80, '*'))\n",
    "print(sample_input[1])\n",
    "print(\"Label of sequence\".center(80, '*'))\n",
    "print(sample_input[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0jn38-qfkHl"
   },
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCFvm152fkHu"
   },
   "source": [
    "For this lab, we will be exploring two variants of RNN: vanilla (or Elman) RNN and LSTM (Long-short term memory). In the following code block, please try to define your own model. Here are some hints.\n",
    "\n",
    "- Each input word is represented by a vector of dimension ```embedding_dim```. Check out ```nn.Embedding``` to see how to initialize embeddings randomly.\n",
    "- Your model should take the following input parameters\n",
    "    - ```hidden_dim```: The number of features in the hidden state h of your RNN layer\n",
    "    - ```output_dim```: Number of output classes\n",
    "    - ```vocab_size``` Size of your vocabulary. \n",
    "    - ```embedding_dim```: Dimension of word embeddings\n",
    "- Your model should consist of an RNN layer (you can use either ```nn.RNN``` or ```nn.LSTM```) followed by a linear layer.\n",
    "- $h_{0}$ (and $c$ if you use LSTM) should be initialized as a zero vector of dimension ```hidden_dim```. You might want to check out ```nn.Parameter```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IX6Hf7xqfkHm"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, \n",
    "                 vocab_size, embedding_dim, rnn='LSTM'):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn_fn = rnn\n",
    "        assert self.rnn_fn in ['LSTM', 'RNN']\n",
    "        self.rnn = getattr(nn, rnn)(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, x_len):\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        # output:  tensor containing the output features (h_t) from the last layer of the RNN, tensor containing the hidden state for t = seq_len.\n",
    "        # pack_padded_sequence: Packs a Tensor containing padded sequences of variable length.\n",
    "        # enforce_sorted: if True, the input is expected to contain sequences sorted by length in a decreasing order. If False, the input will get sorted unconditionally.\n",
    "        _, last_hidden = self.rnn(pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False))\n",
    "        if self.rnn_fn == 'LSTM':\n",
    "            # (h,c)\n",
    "            # c_0: tensor containing the initial cell state for each element in the batch.\n",
    "            last_hidden = last_hidden[0]\n",
    "        out = self.fc(last_hidden.view(-1, self.hidden_dim))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4qTu8mMd1z6",
    "outputId": "6f2f37ff-5a9c-4f6b-bdea-350b0c9125d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8Qrx4KYfkHp"
   },
   "source": [
    "### Train and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nc3scsLfkHq"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader=train_loader, test_loader=test_loader, \n",
    "          learning_rate=0.001, num_epoch=10, print_every=100):\n",
    "    # Training steps\n",
    "    start_time = time.time()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=10**(-5))\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for i, (data, data_len, labels) in enumerate(train_loader):\n",
    "            data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "            outputs = model(data, data_len)\n",
    "            model.zero_grad()\n",
    "            loss = loss_fn(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # report performance\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print('Train set | epoch: {:3d} | {:6d}/{:6d} batches | Loss: {:6.4f}'.format(\n",
    "                    epoch, i + 1, len(train_loader), loss.item()))     \n",
    "    \n",
    "    # Evaluate after every epochh\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "\n",
    "        predictions = []\n",
    "        truths = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, data_len, labels) in enumerate(test_loader):\n",
    "                data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "                outputs = model(data, data_len)\n",
    "                pred = outputs.data.max(-1)[1]\n",
    "                predictions += list(pred.cpu().numpy())\n",
    "                truths += list(labels.cpu().numpy())\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum()\n",
    "                \n",
    "            acc = (100 * correct / total)\n",
    "            auc = roc_auc_score(truths, predictions)\n",
    "            elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "            print('Test set | Accuracy: {:6.4f} | AUC: {:4.2f} | time elapse: {:>9}'.format(\n",
    "                acc, auc, elapse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQMLwClifkHv"
   },
   "source": [
    "Run the code block below to check your model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "seXmatFEfkHw",
    "outputId": "66e275df-700d-4b40-e91b-e9a0f7e961f4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set | epoch:   0 |    100/   302 batches | Loss: 0.5330\n",
      "Train set | epoch:   0 |    200/   302 batches | Loss: 0.5172\n",
      "Train set | epoch:   0 |    300/   302 batches | Loss: 0.3056\n",
      "Test set | Accuracy: 79.8695 | AUC: 0.53 | time elapse:  00:00:03\n",
      "Train set | epoch:   1 |    100/   302 batches | Loss: 0.4811\n",
      "Train set | epoch:   1 |    200/   302 batches | Loss: 0.2720\n",
      "Train set | epoch:   1 |    300/   302 batches | Loss: 0.5370\n",
      "Test set | Accuracy: 82.1062 | AUC: 0.61 | time elapse:  00:00:07\n",
      "Train set | epoch:   2 |    100/   302 batches | Loss: 0.4949\n",
      "Train set | epoch:   2 |    200/   302 batches | Loss: 0.4659\n",
      "Train set | epoch:   2 |    300/   302 batches | Loss: 0.2792\n",
      "Test set | Accuracy: 82.6654 | AUC: 0.65 | time elapse:  00:00:11\n",
      "Train set | epoch:   3 |    100/   302 batches | Loss: 0.3749\n",
      "Train set | epoch:   3 |    200/   302 batches | Loss: 0.2641\n",
      "Train set | epoch:   3 |    300/   302 batches | Loss: 0.4357\n",
      "Test set | Accuracy: 82.5722 | AUC: 0.69 | time elapse:  00:00:15\n",
      "Train set | epoch:   4 |    100/   302 batches | Loss: 0.3739\n",
      "Train set | epoch:   4 |    200/   302 batches | Loss: 0.3519\n",
      "Train set | epoch:   4 |    300/   302 batches | Loss: 0.2975\n",
      "Test set | Accuracy: 83.4110 | AUC: 0.69 | time elapse:  00:00:19\n",
      "Train set | epoch:   5 |    100/   302 batches | Loss: 0.5118\n",
      "Train set | epoch:   5 |    200/   302 batches | Loss: 0.1921\n",
      "Train set | epoch:   5 |    300/   302 batches | Loss: 0.3980\n",
      "Test set | Accuracy: 83.7838 | AUC: 0.68 | time elapse:  00:00:23\n",
      "Train set | epoch:   6 |    100/   302 batches | Loss: 0.2743\n",
      "Train set | epoch:   6 |    200/   302 batches | Loss: 0.2216\n",
      "Train set | epoch:   6 |    300/   302 batches | Loss: 0.3314\n",
      "Test set | Accuracy: 83.4110 | AUC: 0.68 | time elapse:  00:00:26\n",
      "Train set | epoch:   7 |    100/   302 batches | Loss: 0.1499\n",
      "Train set | epoch:   7 |    200/   302 batches | Loss: 0.1611\n",
      "Train set | epoch:   7 |    300/   302 batches | Loss: 0.1619\n",
      "Test set | Accuracy: 83.5974 | AUC: 0.72 | time elapse:  00:00:30\n",
      "Train set | epoch:   8 |    100/   302 batches | Loss: 0.2183\n",
      "Train set | epoch:   8 |    200/   302 batches | Loss: 0.2765\n",
      "Train set | epoch:   8 |    300/   302 batches | Loss: 0.1756\n",
      "Test set | Accuracy: 83.3178 | AUC: 0.72 | time elapse:  00:00:34\n",
      "Train set | epoch:   9 |    100/   302 batches | Loss: 0.1546\n",
      "Train set | epoch:   9 |    200/   302 batches | Loss: 0.0786\n",
      "Train set | epoch:   9 |    300/   302 batches | Loss: 0.1828\n",
      "Test set | Accuracy: 83.5042 | AUC: 0.70 | time elapse:  00:00:38\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "rnn_model = RNN(40, 2, len(vocabulary), 50, rnn='RNN').to(device)\n",
    "train(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "2gzqv_ivfkHz",
    "outputId": "989c5e4e-7b21-4576-bea0-7c8f722dc289",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set | epoch:   0 |    100/   302 batches | Loss: 0.4345\n",
      "Train set | epoch:   0 |    200/   302 batches | Loss: 0.4457\n",
      "Train set | epoch:   0 |    300/   302 batches | Loss: 0.4866\n",
      "Test set | Accuracy: 81.4539 | AUC: 0.59 | time elapse:  00:00:06\n",
      "Train set | epoch:   1 |    100/   302 batches | Loss: 0.3053\n",
      "Train set | epoch:   1 |    200/   302 batches | Loss: 0.4502\n",
      "Train set | epoch:   1 |    300/   302 batches | Loss: 0.3433\n",
      "Test set | Accuracy: 82.6654 | AUC: 0.63 | time elapse:  00:00:12\n",
      "Train set | epoch:   2 |    100/   302 batches | Loss: 0.4614\n",
      "Train set | epoch:   2 |    200/   302 batches | Loss: 0.3137\n",
      "Train set | epoch:   2 |    300/   302 batches | Loss: 0.4248\n",
      "Test set | Accuracy: 84.3430 | AUC: 0.67 | time elapse:  00:00:17\n",
      "Train set | epoch:   3 |    100/   302 batches | Loss: 0.2623\n",
      "Train set | epoch:   3 |    200/   302 batches | Loss: 0.2395\n",
      "Train set | epoch:   3 |    300/   302 batches | Loss: 0.3912\n",
      "Test set | Accuracy: 84.1566 | AUC: 0.71 | time elapse:  00:00:23\n",
      "Train set | epoch:   4 |    100/   302 batches | Loss: 0.1471\n",
      "Train set | epoch:   4 |    200/   302 batches | Loss: 0.2625\n",
      "Train set | epoch:   4 |    300/   302 batches | Loss: 0.2065\n",
      "Test set | Accuracy: 82.6654 | AUC: 0.73 | time elapse:  00:00:30\n",
      "Train set | epoch:   5 |    100/   302 batches | Loss: 0.2897\n",
      "Train set | epoch:   5 |    200/   302 batches | Loss: 0.2586\n",
      "Train set | epoch:   5 |    300/   302 batches | Loss: 0.1315\n",
      "Test set | Accuracy: 84.4362 | AUC: 0.68 | time elapse:  00:00:36\n",
      "Train set | epoch:   6 |    100/   302 batches | Loss: 0.2139\n",
      "Train set | epoch:   6 |    200/   302 batches | Loss: 0.2588\n",
      "Train set | epoch:   6 |    300/   302 batches | Loss: 0.1244\n",
      "Test set | Accuracy: 84.3430 | AUC: 0.70 | time elapse:  00:00:42\n",
      "Train set | epoch:   7 |    100/   302 batches | Loss: 0.0445\n",
      "Train set | epoch:   7 |    200/   302 batches | Loss: 0.3231\n",
      "Train set | epoch:   7 |    300/   302 batches | Loss: 0.1314\n",
      "Test set | Accuracy: 83.0382 | AUC: 0.71 | time elapse:  00:00:49\n",
      "Train set | epoch:   8 |    100/   302 batches | Loss: 0.1747\n",
      "Train set | epoch:   8 |    200/   302 batches | Loss: 0.2470\n",
      "Train set | epoch:   8 |    300/   302 batches | Loss: 0.1581\n",
      "Test set | Accuracy: 84.5294 | AUC: 0.69 | time elapse:  00:00:55\n",
      "Train set | epoch:   9 |    100/   302 batches | Loss: 0.0867\n",
      "Train set | epoch:   9 |    200/   302 batches | Loss: 0.2599\n",
      "Train set | epoch:   9 |    300/   302 batches | Loss: 0.1767\n",
      "Test set | Accuracy: 84.2498 | AUC: 0.71 | time elapse:  00:01:02\n"
     ]
    }
   ],
   "source": [
    "lstm_model = RNN(40, 2, len(vocabulary), 50, rnn='LSTM').to(device)\n",
    "train(lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pz5dadxpfkH2"
   },
   "source": [
    "### Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfn9GiRfqnx2"
   },
   "outputs": [],
   "source": [
    "def sentences_to_padded_index_sequences(words, sentences):\n",
    "    for i, s in enumerate(sentences):\n",
    "        # only take the first pad_length tokens\n",
    "        token_indices = np.array([words[w] if w in words else words['<UNK>'] for w in re.findall(r\"[\\w']+|[.,!?;]\", s.lower())])\n",
    "    return token_indices, len(token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFHMg5TefkH3"
   },
   "outputs": [],
   "source": [
    "def test_sentence(sentence, model):\n",
    "    model.eval()\n",
    "    test_tensor, len_sent = sentences_to_padded_index_sequences(vocab_indices, [sentence])\n",
    "    score = model(torch.LongTensor(test_tensor.astype(int)).unsqueeze(0).to(device), torch.as_tensor([len_sent]).to(device)).data.numpy().squeeze()\n",
    "    label = np.argmax(score)\n",
    "    return (\"positive\" if label == 1 else \"negative\", score[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xAFUwL-MfkH7",
    "outputId": "8138fecb-a7f9-4988-cd07-d4bbef2cef8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('positive', 2.4169722)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"Enjoyed the #GOPDebates and am looking forward to the #DemocraticDebates next.\", lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j689ttEqfkH_",
    "outputId": "b8dfb379-801e-40f1-8839-8256929f1850"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative', 2.8372514)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"Donald Trump is a really nasty piece of work. Hope he disappears quickly. #GOPDebate\", lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNnHlWsFfkIB"
   },
   "source": [
    "## Word Embeddings and How to Use Them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1MwIJMafkIC"
   },
   "source": [
    "When using deep learning methods on NLP tasks, we usually utilize [word embedding](https://en.wikipedia.org/wiki/Word_embedding). To put it briefly, word embedding represent words, or tokens, in a vocabulary as a distributed numerical vector. There are a lot of methods to obtain a word embedding, with some of the most famous shallow models being Word2Vec, GloVe, and FastText while the deeper models are BERT, RoBERTa, T5. It is not difficult to find a general purpose word embedding trained by one of the aforementioned methods on the Internet that's been trained with a massive amount of data. It is usually a good idea to use these pre-trained embedding to save yourself some time and computing resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ta-GpbQpfkID"
   },
   "source": [
    "In this lab, we will be using the [GloVe embedding](https://nlp.stanford.edu/projects/glove/) developed by Stanford,  one of the state-of-the-art word embedding. Please download the file ```glove.6B.50d.txt``` [here](https://drive.google.com/file/d/1JweINiA5JvTNLTm663LH8OdWssK2Kcid/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "6ErZicnmfkIE",
    "outputId": "8e7da543-6b8d-454c-80ca-b986f0edfdba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-f95a23637a13>:4: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec('data/glove.6B.50d.txt', 'tmp_file')\n"
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# load embedding\n",
    "\n",
    "_ = glove2word2vec('data/glove.6B.50d.txt', 'tmp_file')\n",
    "glove_embedding = KeyedVectors.load_word2vec_format('tmp_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGTD_re8fkIH"
   },
   "source": [
    "### Word embedding vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAX0MYIqfkIH"
   },
   "source": [
    "Now we can play around with these vectors to get a sense of how word embeddings can be used to represent words. Here's how you can look up a word embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yravXPPBfkIL"
   },
   "source": [
    "### Find similar words\n",
    "\n",
    "The word embedding vectors can help us find words with similar meanings. Word similarities can be measured by [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). The function below looks up the most similar words to a given word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "PD5uELzwfkIO",
    "outputId": "a8681bba-c1f5-4554-da64-c737af3c6822"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hatred', 0.7746836543083191),\n",
       " ('shame', 0.7489537000656128),\n",
       " ('racist', 0.7371559143066406),\n",
       " ('anyone', 0.7364715933799744),\n",
       " ('bigotry', 0.7300711870193481)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding.similar_by_word('hate', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SiLnfaRHfkIR"
   },
   "source": [
    "### Word arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "eWh4FHadfkIS",
    "outputId": "ced7c845-9b3e-4ff5-f37b-77d04b0b925e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', 0.8109660744667053)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding.similar_by_word(glove_embedding['worse'] - glove_embedding['better'] + glove_embedding['best'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "aPWa4FL4fkIV",
    "outputId": "43ae9327-dca9-44f5-86f1-24a7dd0ed6f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8859834671020508), ('queen', 0.8609582185745239)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding.similar_by_word(glove_embedding['king'] - glove_embedding['man'] + glove_embedding['woman'], topn=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HVI_p6jDfkIY"
   },
   "source": [
    "### Train an LSTM model withh GloVe embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "um2RUjFvfkIZ"
   },
   "source": [
    "Complete the code below. Replace the randomly generated embeddings withh GloVe embeddings. (Hint: check out ```nn.Embedding.weight```). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbqo25l6fkIb"
   },
   "outputs": [],
   "source": [
    "class GloveDataset(Dataset):\n",
    "    def __init__(self, embedding, df, label = 'sentiment'):\n",
    "        self.embedding = embedding\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        sentence = self.df.loc[key,'text']\n",
    "        sentence = re.sub('[\\\\(\\[#.!?,\\'\\/\\])0-9]', ' ', sentence)\n",
    "        \n",
    "        # Deal with recent gensim updates\n",
    "        if int(gensim.__version__[0]) == 4:\n",
    "            token_indices = np.array([self.embedding[word] for word in word_tokenize(sentence.lower()) if word in self.embedding])\n",
    "        else:\n",
    "            token_indices = np.array([self.embedding[word] for word in word_tokenize(sentence.lower()) if word in self.embedding.vocab])\n",
    "        \n",
    "        if len(token_indices):\n",
    "            return (torch.from_numpy(token_indices) , self.df.loc[key, self.label])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def pad_collate_glove(batch):\n",
    "    batch = filter(lambda x:x is not None, batch)\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "\n",
    "    return xx_pad, torch.as_tensor(x_lens), torch.LongTensor(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZZg4ZSOfkIe"
   },
   "outputs": [],
   "source": [
    "# Re-indexing tokens\n",
    "train_loader_glove = DataLoader(GloveDataset(glove_embedding, train_data),\n",
    "                                batch_size = BATCH_SIZE,\n",
    "                                shuffle = True,\n",
    "                                collate_fn = pad_collate_glove)\n",
    "test_loader_glove = DataLoader(GloveDataset(glove_embedding, test_data),\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               shuffle=True,\n",
    "                               collate_fn = pad_collate_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "4Bo2pFPqfkIh",
    "outputId": "856ef279-7a91-4c41-b79f-aa540f832471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set | epoch:   0 |    100/   302 batches | Loss: 0.4955\n",
      "Train set | epoch:   0 |    200/   302 batches | Loss: 0.4322\n",
      "Train set | epoch:   0 |    300/   302 batches | Loss: 0.6698\n",
      "Test set | Accuracy: 80.5219 | AUC: 0.59 | time elapse:  00:00:05\n",
      "Train set | epoch:   1 |    100/   302 batches | Loss: 0.2929\n",
      "Train set | epoch:   1 |    200/   302 batches | Loss: 0.4945\n",
      "Train set | epoch:   1 |    300/   302 batches | Loss: 0.5564\n",
      "Test set | Accuracy: 82.9450 | AUC: 0.67 | time elapse:  00:00:10\n",
      "Train set | epoch:   2 |    100/   302 batches | Loss: 0.4828\n",
      "Train set | epoch:   2 |    200/   302 batches | Loss: 0.4426\n",
      "Train set | epoch:   2 |    300/   302 batches | Loss: 0.3756\n",
      "Test set | Accuracy: 82.9450 | AUC: 0.64 | time elapse:  00:00:15\n",
      "Train set | epoch:   3 |    100/   302 batches | Loss: 0.1594\n",
      "Train set | epoch:   3 |    200/   302 batches | Loss: 0.4944\n",
      "Train set | epoch:   3 |    300/   302 batches | Loss: 0.3339\n",
      "Test set | Accuracy: 82.5722 | AUC: 0.71 | time elapse:  00:00:20\n",
      "Train set | epoch:   4 |    100/   302 batches | Loss: 0.2891\n",
      "Train set | epoch:   4 |    200/   302 batches | Loss: 0.2421\n",
      "Train set | epoch:   4 |    300/   302 batches | Loss: 0.3354\n",
      "Test set | Accuracy: 83.7838 | AUC: 0.71 | time elapse:  00:00:25\n",
      "Train set | epoch:   5 |    100/   302 batches | Loss: 0.2754\n",
      "Train set | epoch:   5 |    200/   302 batches | Loss: 0.3772\n",
      "Train set | epoch:   5 |    300/   302 batches | Loss: 0.3851\n",
      "Test set | Accuracy: 84.0634 | AUC: 0.67 | time elapse:  00:00:30\n",
      "Train set | epoch:   6 |    100/   302 batches | Loss: 0.2236\n",
      "Train set | epoch:   6 |    200/   302 batches | Loss: 0.2710\n",
      "Train set | epoch:   6 |    300/   302 batches | Loss: 0.4589\n",
      "Test set | Accuracy: 83.6906 | AUC: 0.74 | time elapse:  00:00:35\n",
      "Train set | epoch:   7 |    100/   302 batches | Loss: 0.3611\n",
      "Train set | epoch:   7 |    200/   302 batches | Loss: 0.3928\n",
      "Train set | epoch:   7 |    300/   302 batches | Loss: 0.4121\n",
      "Test set | Accuracy: 84.8089 | AUC: 0.69 | time elapse:  00:00:40\n",
      "Train set | epoch:   8 |    100/   302 batches | Loss: 0.3887\n",
      "Train set | epoch:   8 |    200/   302 batches | Loss: 0.1635\n",
      "Train set | epoch:   8 |    300/   302 batches | Loss: 0.2167\n",
      "Test set | Accuracy: 84.9021 | AUC: 0.73 | time elapse:  00:00:45\n",
      "Train set | epoch:   9 |    100/   302 batches | Loss: 0.2651\n",
      "Train set | epoch:   9 |    200/   302 batches | Loss: 0.4149\n",
      "Train set | epoch:   9 |    300/   302 batches | Loss: 0.2249\n",
      "Test set | Accuracy: 84.3430 | AUC: 0.72 | time elapse:  00:00:50\n"
     ]
    }
   ],
   "source": [
    "glove_model = RNN(40, 2, len(vocabulary), 50, rnn='LSTM')\n",
    "# nn.Identity can fill in gaps to provide a consistent architecture.\n",
    "glove_model.emb = nn.Identity()\n",
    "train(glove_model.to(device), train_loader=train_loader_glove, test_loader=test_loader_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKwQwYI6BIwg"
   },
   "source": [
    "In the last case we just used the embedding without training it. Let's try and train the GloVe embedding to see if that increases the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t-3_a6UkzZwa",
    "outputId": "5d279ed6-4e40-4bae-fb1a-de16e6be6bed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:05, 69768.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# load embedding\n",
    "emb_dim = 50\n",
    "with open('data/glove.6B.50d.txt') as f:\n",
    "    glove_embedding = []\n",
    "    words = {}\n",
    "    chars = {}\n",
    "    idx2words = {}\n",
    "    ordered_words = []\n",
    "\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        s = line.split()\n",
    "        glove_embedding.append(np.asarray(s[1:]))\n",
    "        \n",
    "        words[s[0]] = len(words)\n",
    "        idx2words[i] = s[0]\n",
    "        ordered_words.append(s[0])\n",
    "        \n",
    "# add unknown to word and char\n",
    "glove_embedding.append(np.random.rand(emb_dim))\n",
    "words[\"<UNK>\"] = len(words)\n",
    "\n",
    "# add padding\n",
    "glove_embedding.append(np.zeros(emb_dim))\n",
    "words[\"<PAD>\"] = len(words)\n",
    "\n",
    "chars[\"<UNK>\"] = len(chars)\n",
    "chars[\"<PAD>\"] = len(chars)\n",
    "\n",
    "glove_embedding = np.array(glove_embedding).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxEG3l-izy0N"
   },
   "outputs": [],
   "source": [
    "train_loader_glove = DataLoader(TweetDataset(words, train_data),\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True,\n",
    "                                collate_fn = pad_collate)\n",
    "test_loader_glove = DataLoader(TweetDataset(words, test_data),\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               shuffle=True,\n",
    "                               collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "id": "64PinsMTfkIk",
    "outputId": "2e352d15-409d-492a-8b03-861873096070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set | epoch:   0 |    100/   302 batches | Loss: 0.6346\n",
      "Train set | epoch:   0 |    200/   302 batches | Loss: 0.3434\n",
      "Train set | epoch:   0 |    300/   302 batches | Loss: 0.5903\n",
      "Test set | Accuracy: 80.8947 | AUC: 0.59 | time elapse:  00:00:22\n",
      "Train set | epoch:   1 |    100/   302 batches | Loss: 0.4892\n",
      "Train set | epoch:   1 |    200/   302 batches | Loss: 0.4271\n",
      "Train set | epoch:   1 |    300/   302 batches | Loss: 0.4497\n",
      "Test set | Accuracy: 83.8770 | AUC: 0.68 | time elapse:  00:00:44\n",
      "Train set | epoch:   2 |    100/   302 batches | Loss: 0.3000\n",
      "Train set | epoch:   2 |    200/   302 batches | Loss: 0.3587\n",
      "Train set | epoch:   2 |    300/   302 batches | Loss: 0.1875\n",
      "Test set | Accuracy: 84.6226 | AUC: 0.72 | time elapse:  00:01:07\n",
      "Train set | epoch:   3 |    100/   302 batches | Loss: 0.2807\n",
      "Train set | epoch:   3 |    200/   302 batches | Loss: 0.1064\n",
      "Train set | epoch:   3 |    300/   302 batches | Loss: 0.1865\n",
      "Test set | Accuracy: 83.9702 | AUC: 0.75 | time elapse:  00:01:29\n",
      "Train set | epoch:   4 |    100/   302 batches | Loss: 0.2241\n",
      "Train set | epoch:   4 |    200/   302 batches | Loss: 0.1761\n",
      "Train set | epoch:   4 |    300/   302 batches | Loss: 0.1187\n",
      "Test set | Accuracy: 84.9021 | AUC: 0.68 | time elapse:  00:01:51\n",
      "Train set | epoch:   5 |    100/   302 batches | Loss: 0.3002\n",
      "Train set | epoch:   5 |    200/   302 batches | Loss: 0.0486\n",
      "Train set | epoch:   5 |    300/   302 batches | Loss: 0.1215\n",
      "Test set | Accuracy: 84.5294 | AUC: 0.72 | time elapse:  00:02:12\n",
      "Train set | epoch:   6 |    100/   302 batches | Loss: 0.1530\n",
      "Train set | epoch:   6 |    200/   302 batches | Loss: 0.2896\n",
      "Train set | epoch:   6 |    300/   302 batches | Loss: 0.1230\n",
      "Test set | Accuracy: 84.3430 | AUC: 0.71 | time elapse:  00:02:34\n",
      "Train set | epoch:   7 |    100/   302 batches | Loss: 0.0623\n",
      "Train set | epoch:   7 |    200/   302 batches | Loss: 0.1114\n",
      "Train set | epoch:   7 |    300/   302 batches | Loss: 0.0759\n",
      "Test set | Accuracy: 83.6906 | AUC: 0.72 | time elapse:  00:02:56\n",
      "Train set | epoch:   8 |    100/   302 batches | Loss: 0.0119\n",
      "Train set | epoch:   8 |    200/   302 batches | Loss: 0.1400\n",
      "Train set | epoch:   8 |    300/   302 batches | Loss: 0.1284\n",
      "Test set | Accuracy: 83.2246 | AUC: 0.72 | time elapse:  00:03:18\n",
      "Train set | epoch:   9 |    100/   302 batches | Loss: 0.0556\n",
      "Train set | epoch:   9 |    200/   302 batches | Loss: 0.0303\n",
      "Train set | epoch:   9 |    300/   302 batches | Loss: 0.0273\n",
      "Test set | Accuracy: 83.1314 | AUC: 0.73 | time elapse:  00:03:39\n"
     ]
    }
   ],
   "source": [
    "glove_model = RNN(40, 2, len(glove_embedding), 50, rnn='LSTM')\n",
    "glove_model.emb.weight.data.copy_(torch.from_numpy(glove_embedding))\n",
    "train(glove_model, train_loader=train_loader_glove, test_loader=test_loader_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "go446RJJBUw9"
   },
   "source": [
    "The model seems to have overfit here. We can increase the regularization through weight decay/dropout to get better results."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab7_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
